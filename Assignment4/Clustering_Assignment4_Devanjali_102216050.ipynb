{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiPK-7GfJ1rJ",
        "outputId": "796845b6-37ff-4d0d-84b9-bfcea4697c30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "KMeans Clustering Results:\n",
            "Preprocessing  Clusters  Silhouette  Calinski-Harabasz  Davies-Bouldin\n",
            "No Processing         3        0.55              562.0            0.66\n",
            "No Processing         4        0.50              531.0            0.78\n",
            "No Processing         5        0.49              496.0            0.81\n",
            "Normalization         3        0.50              360.0            0.76\n",
            "Normalization         4        0.45              314.0            0.90\n",
            "Normalization         5        0.35              289.0            0.96\n",
            "    Transform         3        0.57              974.0            0.63\n",
            "    Transform         4        0.50              839.0            0.77\n",
            "    Transform         5        0.34              722.0            1.08\n",
            "          PCA         3        0.60              694.0            0.56\n",
            "          PCA         4        0.56              718.0            0.60\n",
            "          PCA         5        0.55              685.0            0.63\n",
            "          T+N         3        0.49              440.0            0.78\n",
            "          T+N         4        0.44              364.0            0.91\n",
            "          T+N         5        0.33              342.0            1.02\n",
            "      T+N+PCA         3        0.55              575.0            0.65\n",
            "      T+N+PCA         4        0.52              509.0            0.70\n",
            "      T+N+PCA         5        0.43              527.0            0.78\n",
            "Saved to kmeans_results.csv\n",
            "Table saved as 'kmeans_results.png'\n",
            "\n",
            "Hierarchical Clustering Results:\n",
            "Preprocessing  Clusters  Silhouette  Calinski-Harabasz  Davies-Bouldin\n",
            "No Processing         3        0.55              558.0            0.66\n",
            "No Processing         4        0.49              515.0            0.80\n",
            "No Processing         5        0.48              488.0            0.82\n",
            "Normalization         3        0.50              349.0            0.75\n",
            "Normalization         4        0.43              301.0            0.85\n",
            "Normalization         5        0.35              272.0            0.91\n",
            "    Transform         3        0.57              974.0            0.63\n",
            "    Transform         4        0.50              787.0            0.72\n",
            "    Transform         5        0.43              671.0            0.84\n",
            "          PCA         3        0.60              689.0            0.56\n",
            "          PCA         4        0.54              674.0            0.65\n",
            "          PCA         5        0.55              666.0            0.65\n",
            "          T+N         3        0.48              406.0            0.77\n",
            "          T+N         4        0.42              348.0            0.88\n",
            "          T+N         5        0.32              323.0            1.00\n",
            "      T+N+PCA         3        0.53              504.0            0.59\n",
            "      T+N+PCA         4        0.50              479.0            0.62\n",
            "      T+N+PCA         5        0.41              476.0            0.72\n",
            "Saved to hierarchical_results.csv\n",
            "Table saved as 'hierarchical_results.png'\n",
            "\n",
            "MeanShift Clustering Results:\n",
            "Preprocessing  Clusters  Bandwidth  Silhouette  Calinski-Harabasz  Davies-Bouldin\n",
            "No Processing         2     0.9095        0.69              510.0            0.39\n",
            "Normalization         3     0.2761        0.48              290.0            0.76\n",
            "    Transform         3     0.2073        0.57              969.0            0.63\n",
            "          PCA         3     0.7830        0.56              615.0            0.56\n",
            "          T+N         3     0.2643        0.54              278.0            0.67\n",
            "      T+N+PCA         4     0.2223        0.42              256.0            0.74\n",
            "Saved to meanshift_results.csv\n",
            "Table saved as 'meanshift_results.png'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans, MeanShift, estimate_bandwidth, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import table\n",
        "\n",
        "# Load the dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "\n",
        "# Preprocessing Functions\n",
        "def normalize(data): return MinMaxScaler().fit_transform(data)\n",
        "def transform(data): return np.log1p(data)\n",
        "def apply_pca(data, n=2): return PCA(n_components=n).fit_transform(data)\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate_clustering(X, labels):\n",
        "    if len(np.unique(labels)) < 2:\n",
        "        return [None, None, None]\n",
        "    return [\n",
        "        round(silhouette_score(X, labels), 2),\n",
        "        round(calinski_harabasz_score(X, labels), 0),\n",
        "        round(davies_bouldin_score(X, labels), 2),\n",
        "    ]\n",
        "\n",
        "# Prepare preprocessing pipelines\n",
        "preprocessing_techniques = {\n",
        "    'No Processing': lambda x: x,\n",
        "    'Normalization': normalize,\n",
        "    'Transform': transform,\n",
        "    'PCA': lambda x: apply_pca(x),\n",
        "    'T+N': lambda x: normalize(transform(x)),\n",
        "    'T+N+PCA': lambda x: apply_pca(normalize(transform(x))),\n",
        "}\n",
        "\n",
        "# Cluster counts for KMeans and Hierarchical\n",
        "cluster_counts = [3, 4, 5]\n",
        "\n",
        "def perform_clustering_analysis():\n",
        "    all_results = {}\n",
        "\n",
        "    # KMeans and Hierarchical Clustering\n",
        "    for algo in ['KMeans', 'Hierarchical']:\n",
        "        algo_results = []\n",
        "        for method_name, prep_func in preprocessing_techniques.items():\n",
        "            X_prep = prep_func(X)\n",
        "            for k in cluster_counts:\n",
        "                if algo == 'KMeans':\n",
        "                    model = KMeans(n_clusters=k, n_init=10)\n",
        "                else:\n",
        "                    model = AgglomerativeClustering(n_clusters=k)\n",
        "\n",
        "                labels = model.fit_predict(X_prep)\n",
        "                scores = evaluate_clustering(X_prep, labels)\n",
        "\n",
        "                algo_results.append({\n",
        "                    'Preprocessing': method_name,\n",
        "                    'Clusters': k,\n",
        "                    'Silhouette': scores[0],\n",
        "                    'Calinski-Harabasz': scores[1],\n",
        "                    'Davies-Bouldin': scores[2],\n",
        "                })\n",
        "\n",
        "        all_results[algo] = pd.DataFrame(algo_results)\n",
        "\n",
        "    # MeanShift Clustering\n",
        "    ms_results = []\n",
        "    for method_name, prep_func in preprocessing_techniques.items():\n",
        "        X_prep = prep_func(X)\n",
        "        bandwidth = estimate_bandwidth(X_prep, quantile=0.2)\n",
        "        model = MeanShift(bandwidth=bandwidth)\n",
        "        labels = model.fit_predict(X_prep)\n",
        "        scores = evaluate_clustering(X_prep, labels)\n",
        "\n",
        "        ms_results.append({\n",
        "            'Preprocessing': method_name,\n",
        "            'Clusters': len(np.unique(labels)),\n",
        "            'Bandwidth': round(bandwidth, 4),\n",
        "            'Silhouette': scores[0],\n",
        "            'Calinski-Harabasz': scores[1],\n",
        "            'Davies-Bouldin': scores[2],\n",
        "        })\n",
        "\n",
        "    all_results['MeanShift'] = pd.DataFrame(ms_results)\n",
        "    return all_results\n",
        "\n",
        "def save_table_as_png(df, filename, extra_cols=None):\n",
        "    fig, ax = plt.subplots(figsize=(12, max(4, len(df)/2)))\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Create table and style it\n",
        "    tbl = table(ax, df, loc='center', cellLoc='center')\n",
        "    tbl.auto_set_font_size(False)\n",
        "    tbl.set_fontsize(10)\n",
        "    tbl.scale(1.2, 1.2)\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Table saved as '{filename}'\")\n",
        "\n",
        "# Perform all clustering analyses\n",
        "results = perform_clustering_analysis()\n",
        "\n",
        "# Save results for each algorithm\n",
        "for algo, df in results.items():\n",
        "    print(f\"\\n{algo} Clustering Results:\")\n",
        "    print(df.to_string(index=False))\n",
        "\n",
        "    # Save to CSV\n",
        "    csv_file = f\"{algo.lower()}_results.csv\"\n",
        "    df.to_csv(csv_file, index=False)\n",
        "    print(f\"Saved to {csv_file}\")\n",
        "\n",
        "    # Save to PNG\n",
        "    png_file = f\"{algo.lower()}_results.png\"\n",
        "    save_table_as_png(df, png_file)"
      ]
    }
  ]
}